# Online Learning Configuration
# This configuration runs ONLY online learning with a pre-trained model
# To use this config:
# 1. Ensure model_path points to a valid model file (check 'ls -la experiments/results/checkpoints/')
# 2. Run: python main.py simulate -c configs/online_learning_config.yaml -o experiments/results/online_learning_test

system_model:
  N: 8  # number of antennas
  M: 3   # number of sources
  T: 200  # number of snapshots
  snr: 10  # signal-to-noise ratio in dB
  field_type: "far"  # "near" or "far"
  signal_nature: "non-coherent"  # "non-coherent" or "coherent"
  signal_type: "narrowband"  # "narrowband" only supported currently
  wavelength: 1  # carrier wavelength in meters
  eta: 0.0  # steering vector uniform error variance
  bias: 0  # steering vector bias error
  sv_noise_var: 0.0  # steering vector additive gaussian error noise variance
  doa_range: 60  # range of DOA values [-doa_range, doa_range]
  doa_resolution: 1  # resolution of DOA values in degrees
  max_range_ratio_to_limit: 0.5  # ratio of maximum range to Fraunhofer distance
  range_resolution: 1  # resolution of range values in meters

dataset:
  samples_size: 256  # overall dataset size
  train_test_ratio: 1  # ratio between train and test datasets
  create_data: true  # whether to create new data or use existing data
  save_dataset: false  # whether to save the dataset
  true_doa_train: null  # predefined angles for training (null for random)
  true_range_train: null  # predefined ranges for training (null for random)
  true_doa_test: null  # predefined angles for testing (null for random)
  true_range_test: null  # predefined ranges for testing (null for random)

model:
  type: "SubspaceNet"  # SubspaceNet, DCD-MUSIC
  params:
    diff_method: "esprit"  # esprit, music_1D, music_2D, beamformer
    train_loss_type: "rmspe"  # music_spectrum, rmspe
    tau: 8  # number of autocorrelation lags
    field_type: "Far"  # Far, Near
    regularization: "null"  # aic, mdl, threshold, null
    variant: "small"  # big, small
    norm_layer: false
    batch_norm: false

# Disable regular training
training:
  enabled: false
  epochs: 30
  batch_size: 256
  optimizer: "Adam"
  scheduler: "ReduceLROnPlateau"
  learning_rate: 0.001
  weight_decay: 1e-9
  step_size: 50
  gamma: 0.5
  training_objective: "angle"
  save_checkpoint: true

# CRITICAL: Model loading must happen before online learning
# Keep load_model true and provide a valid model path
simulation:
  train_model: false
  evaluate_model: false
  load_model: true  # IMPORTANT: Must be true to load model before online learning
  save_model: true
  plot_results: true
  save_plots: true
  # Use an existing model file found in the checkpoints directory
  model_path: "experiments/results/checkpoints/saved_SubspaceNet_20250517_140017.pt"  # Latest model from May 17, 2025
  subspace_methods: []  # No classic methods needed for online learning

evaluation: {}

# Enable trajectory with longer sequence for online learning
trajectory:
  enabled: true
  trajectory_type: "random_walk"
  trajectory_length: 200  # Longer trajectory for online learning
  random_walk_std_dev: 5.0  # standard deviation for random walk trajectory (degrees)
  save_trajectory: false 

kalman_filter:
  process_noise_std_dev: null  # standard deviation of process noise (degrees), null to use trajectory.random_walk_std_dev
  measurement_noise_std_dev: 1.0e-3  # standard deviation of measurement noise (degrees)
  initial_covariance: 1.0  # initial state covariance

# Enable online learning with appropriate parameters
online_learning:
  enabled: true  # Enable online learning
  window_size: 20  # Size of sliding window
  stride: 10  # Step size for sliding window
  loss_threshold: 0.5  # Threshold for detecting drift and triggering online learning
  max_iterations: 10  # Maximum iterations for online training
  learning_rate: 0.0001  # Learning rate for online training (smaller than main training)
  trajectory_length: 500  # Length of trajectory specifically for online learning

  # Dynamic Eta Update Parameters - ADDED
  eta_update_interval_windows: 10  # Update eta every 10 windows
  eta_increment: 0.02             # Increase eta by 0.02 each time
  max_eta: 0.5                    # Don't let eta go above 0.5
  min_eta: 0.0                    # Don't let eta go below 0.0

# No scenarios defined here, as this config is for a single online learning run
scenarios: null
train_base_model_only_once: true 
scenario_config: null 